{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nama file: terusan_sulfat_utara\n"
     ]
    }
   ],
   "source": [
    "video_path = 'videos/terusan_sulfat_utara.mp4'\n",
    "video_name = os.path.basename(video_path)\n",
    "file_name = os.path.splitext(video_name)[0]\n",
    "\n",
    "print(\"Nama file:\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\whisn/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-27 Python-3.9.16 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce GTX 1660 Ti with Max-Q Design, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: 161\ty1:52\tx2:220\ty2:164\n",
      "area:6608\n",
      "x1: 155\ty1:62\tx2:214\ty2:174\n",
      "area:6608\n",
      "x1: 150\ty1:73\tx2:208\ty2:186\n",
      "area:6554\n",
      "x1: 167\ty1:0\tx2:226\ty2:91\n",
      "area:5369\n",
      "x1: 162\ty1:0\tx2:223\ty2:100\n",
      "area:6100\n",
      "x1: 158\ty1:3\tx2:215\ty2:106\n",
      "area:5871\n",
      "x1: 148\ty1:3\tx2:210\ty2:123\n",
      "area:7440\n",
      "x1: 139\ty1:0\tx2:205\ty2:138\n",
      "area:9108\n",
      "x1: 134\ty1:38\tx2:192\ty2:148\n",
      "area:6380\n",
      "x1: 129\ty1:42\tx2:194\ty2:158\n",
      "area:7540\n",
      "x1: 124\ty1:52\tx2:189\ty2:168\n",
      "area:7540\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "cap=cv2.VideoCapture(video_path)\n",
    "n = 0\n",
    "detected_motorcycles = []\n",
    "\n",
    "while True: \n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    frame=cv2.resize(frame,(1020,600))\n",
    "    roi = frame[320:590, 450:790]\n",
    "    results = model(roi)\n",
    "   \n",
    "    for index, row in results.pandas().xyxy[0].iterrows(): \n",
    "        \n",
    "        x1 = int(row['xmin'])\n",
    "        y1 = int(row['ymin'])\n",
    "        x2 = int(row['xmax'])\n",
    "        y2 = int(row['ymax'])\n",
    "        d=(row['name'])\n",
    "        # print(row.keys())\n",
    "     \n",
    "        if 'motorcycle' in d:\n",
    "            motor_area = roi[y1:y2, x1:x2]\n",
    "            total_pixels = motor_area.shape[0] * motor_area.shape[1]\n",
    "            actual_w = x2-x1\n",
    "            actual_h = y2-y1\n",
    "            if (total_pixels >= 3000) and ((actual_h/actual_w) >= 1.45):\n",
    "                n += 1\n",
    "                cv2.rectangle(roi, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.imwrite(\"result/roi-motor/yolo/\"+ file_name + '/' + str(n)+'.jpg', roi[y1:y2, x1:x2])\n",
    "                print(f'x1: {x1}\\ty1:{y1}\\tx2:{x2}\\ty2:{y2}\\narea:{total_pixels}')\n",
    "        \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Roi\", roi)\n",
    "    if cv2.waitKey(1) &0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
